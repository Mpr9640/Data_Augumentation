{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mpr9640/Data_Augumentation/blob/main/Simple_Data_Augmentation_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6746f419-75e0-4ba8-b379-48a52b612e00",
      "metadata": {
        "id": "6746f419-75e0-4ba8-b379-48a52b612e00",
        "outputId": "7e2e6afc-d3d4-40aa-b9d0-030b597665a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: Reshape and normalize\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Selecting a smaller subset for training to demonstrate how data augmentation can help\n",
        "subset_indices = np.random.choice(train_images.shape[0], 500, replace=False)\n",
        "train_images_subset = train_images[subset_indices]\n",
        "train_labels_subset = train_labels[subset_indices]\n",
        "\n",
        "# Function to display a grid of images\n",
        "def display_images(images, labels, num_rows=2, num_cols=5):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(num_rows * num_cols):\n",
        "        plt.subplot(num_rows, num_cols, i + 1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f'Label: {labels[i]}')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display the first few images and their labels\n",
        "display_images(train_images, train_labels.argmax(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b482d35-bb2b-4a0f-acd8-5ad5fde0a319",
      "metadata": {
        "id": "0b482d35-bb2b-4a0f-acd8-5ad5fde0a319"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada9e088-5263-481e-903d-2d4e792b5204",
      "metadata": {
        "id": "ada9e088-5263-481e-903d-2d4e792b5204",
        "outputId": "fd968f76-c505-427d-c81b-cd0a42db2caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-11 01:20:21.877117: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2024-04-11 01:20:21.877142: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-04-11 01:20:21.877148: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-04-11 01:20:21.877200: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-04-11 01:20:21.877217: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/16 [>.............................] - ETA: 5s - loss: 2.3144 - accuracy: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-11 01:20:22.264338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 13ms/step - loss: 1.6328 - accuracy: 0.4560\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7690 - accuracy: 0.7480\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4185 - accuracy: 0.8740\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2626 - accuracy: 0.9180\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9540\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9700\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9880\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.9940\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 0.9980\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 9.5122e-04 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.6081e-04 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.0898e-04 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.3896e-04 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.9217e-04 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.2419e-04 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.6936e-04 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.4333e-04 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.0143e-04 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.6686e-04 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.3746e-04 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.1088e-04 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.8378e-04 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.8033e-04 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.6026e-04 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.2518e-04 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.1372e-04 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.0016e-04 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.7995e-04 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.6332e-04 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.4771e-04 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.4196e-04 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.3241e-04 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.1528e-04 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.0611e-04 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.9842e-04 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.9043e-04 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.8665e-04 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.7189e-04 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.6751e-04 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.6505e-04 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.5890e-04 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.4653e-04 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.4385e-04 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.3873e-04 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.3243e-04 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.2737e-04 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.2449e-04 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.1891e-04 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.1458e-04 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.1083e-04 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.0855e-04 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.0410e-04 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.0130e-04 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 9.7546e-05 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 9.4696e-05 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 9.2445e-05 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.8946e-05 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.6246e-05 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.3795e-05 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 8.2068e-05 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.9236e-05 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.6910e-05 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.4558e-05 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.2388e-05 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.0606e-05 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.8598e-05 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.6835e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.5446e-05 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.3296e-05 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.1564e-05 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.9711e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.8583e-05 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.7265e-05 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.5954e-05 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.4832e-05 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.3142e-05 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.1873e-05 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5.0494e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.9032e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.8639e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.6728e-05 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.5956e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.4757e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.3465e-05 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.2611e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 4.1876e-05 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.0928e-05 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.0027e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.9102e-05 - accuracy: 1.0000\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.8056 - accuracy: 0.8921\n",
            "test loss without augmentation: 0.8056265115737915\n",
            "test accuracy without augmentation: 0.8920999765396118\n"
          ]
        }
      ],
      "source": [
        "model_without_aug = create_model()\n",
        "model_without_aug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_without_aug.fit(train_images_subset, train_labels_subset, epochs=100)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model_without_aug.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"test loss without augmentation: {test_loss}\")\n",
        "print(f\"test accuracy without augmentation: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e88fe9f-83a5-4a70-9d5e-0820c559a786",
      "metadata": {
        "id": "9e88fe9f-83a5-4a70-9d5e-0820c559a786",
        "outputId": "4a4128db-eac2-4d6e-e26e-9b82ba9ca592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 2.1984 - accuracy: 0.2060\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.6708 - accuracy: 0.4100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.2972 - accuracy: 0.5840\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.0981 - accuracy: 0.6440\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.8208 - accuracy: 0.7420\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7743 - accuracy: 0.7660\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5872 - accuracy: 0.8080\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5392 - accuracy: 0.8340\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.8020\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.8540\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3710 - accuracy: 0.8840\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3776 - accuracy: 0.8740\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3254 - accuracy: 0.8940\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3436 - accuracy: 0.8820\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2443 - accuracy: 0.9240\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3119 - accuracy: 0.9080\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2837 - accuracy: 0.9160\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2387 - accuracy: 0.9180\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3485 - accuracy: 0.8880\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2684 - accuracy: 0.9080\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2978 - accuracy: 0.9120\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2675 - accuracy: 0.9100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1885 - accuracy: 0.9400\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2723 - accuracy: 0.9120\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2489 - accuracy: 0.9140\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2127 - accuracy: 0.9320\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1692 - accuracy: 0.9320\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2610 - accuracy: 0.9160\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2726 - accuracy: 0.9220\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2935 - accuracy: 0.9120\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.9400\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2356 - accuracy: 0.9260\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.9120\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.9220\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2313 - accuracy: 0.9280\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2144 - accuracy: 0.9380\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2006 - accuracy: 0.9340\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1569 - accuracy: 0.9380\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2845 - accuracy: 0.9300\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2958 - accuracy: 0.9280\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3238 - accuracy: 0.9160\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2537 - accuracy: 0.9240\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.9140\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3573 - accuracy: 0.9200\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2574 - accuracy: 0.9300\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.9300\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1963 - accuracy: 0.9380\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1514 - accuracy: 0.9440\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.9460\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9580\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2548 - accuracy: 0.9380\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1797 - accuracy: 0.9380\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.9300\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2244 - accuracy: 0.9340\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3718 - accuracy: 0.9320\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2109 - accuracy: 0.9340\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2181 - accuracy: 0.9600\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3399 - accuracy: 0.9340\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.9020\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2804 - accuracy: 0.9500\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3084 - accuracy: 0.9400\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1638 - accuracy: 0.9560\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2625 - accuracy: 0.9400\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2627 - accuracy: 0.9420\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4571 - accuracy: 0.9120\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.9260\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4840 - accuracy: 0.9240\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.9280\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.8600 - accuracy: 0.8980\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7278 - accuracy: 0.8920\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5660 - accuracy: 0.9040\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5104 - accuracy: 0.9360\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2849 - accuracy: 0.9500\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5120 - accuracy: 0.9180\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7626 - accuracy: 0.9100\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.9160\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.9776 - accuracy: 0.8960\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7817 - accuracy: 0.9240\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7692 - accuracy: 0.9120\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.1527 - accuracy: 0.8960\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.7959 - accuracy: 0.8840\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.3722 - accuracy: 0.8820\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.5972 - accuracy: 0.8900\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.2661 - accuracy: 0.8700\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.2443 - accuracy: 0.8820\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.7110 - accuracy: 0.9060\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.4774 - accuracy: 0.8480\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.9499 - accuracy: 0.8940\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 2.1405 - accuracy: 0.8860\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.5127 - accuracy: 0.8720\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.1726 - accuracy: 0.9180\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.1856 - accuracy: 0.9140\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 3.0788 - accuracy: 0.8920\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.6671 - accuracy: 0.8480\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.0348 - accuracy: 0.8940\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.2393 - accuracy: 0.8900\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.8200 - accuracy: 0.8680\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 4.7437 - accuracy: 0.8880\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.8901 - accuracy: 0.8560\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.1582 - accuracy: 0.8760\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 5.8956 - accuracy: 0.9047\n",
            "test loss with augmentation: 5.895603656768799\n",
            "test accuracy with augmentation: 0.904699981212616\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "# Prepare the model\n",
        "model_with_aug = create_model()\n",
        "model_with_aug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "augmented_data_generator = data_augmentation.flow(train_images_subset, train_labels_subset, batch_size=32)\n",
        "\n",
        "# Train the model with data augmentation\n",
        "model_with_aug.fit(augmented_data_generator, epochs=100)\n",
        "\n",
        "# Evaluate the target_model on the test set\n",
        "test_loss, test_acc = model_with_aug.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"test loss with augmentation: {test_loss}\")\n",
        "print(f\"test accuracy with augmentation: {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf_metal)",
      "language": "python",
      "name": "tf_metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}